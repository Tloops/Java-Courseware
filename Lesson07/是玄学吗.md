# 是玄学吗

## 题目在这里~

这个是计算机初学者可能不能理解的问题……

来看下面这段代码：

```java
double t = 0.2;
for(int i = 0; i < 50; i++) {
	System.out.println(t);
	t = 1 - 4 * t;
}
```

输出是什么？不知道的话请自己试试哦！（解释在下面！）















## 解释

稍微有点编程基础的人会说，这好像会打印出来50行，每行一个0.2？



按照这段程序的逻辑来说是的确这样的，但是实际的输出是这样的：

```
0.2
0.19999999999999996
0.20000000000000018
0.1999999999999993
0.20000000000000284
0.19999999999998863
0.20000000000004547
0.1999999999998181
0.2000000000007276
0.19999999999708962
0.20000000001164153
0.19999999995343387
0.20000000018626451
0.19999999925494194
0.20000000298023224
0.19999998807907104
0.20000004768371582
0.19999980926513672
0.20000076293945312
0.1999969482421875
0.20001220703125
0.199951171875
0.2001953125
0.19921875
0.203125
0.1875
0.25
0.0
1.0
-3.0
13.0
-51.0
205.0
-819.0
3277.0
-13107.0
52429.0
-209715.0
838861.0
-3355443.0
1.3421773E7
-5.3687091E7
2.14748365E8
-8.58993459E8
3.435973837E9
-1.3743895347E10
5.4975581389E10
-2.19902325555E11
8.79609302221E11
-3.518437208883E12
```

不难发现，误差越来越大，越来越偏离原来的0.2

误差从何而来？我们知道计算机是用二进制来表示数的，那么0.2该如何表示？

$0.2_{(10)} = 0.0011001100110011..._{(2)}$

最后应当是0011**无限循环**下去的，也就是说0.2是不可能被**有限**位数的double数据类型精确表示的。

这就像是一种蝴蝶效应，原本double表示0.2的精度的微小误差被`*4`一次次放大，最后误差甚至都到达了$10^{11}$之多。

不过不用担心在日常的编程过程中会出现这样的问题，因为我们一般都会使用四舍五入（`System.out.printf("%.2f", t);`）浮点数运算的结果，而且在以$10^{-5}$为标准的精度下，做20次这样的乘法以及减法运算才出现了这样的误差，在日常的编程中，还是比较容易避免的。

